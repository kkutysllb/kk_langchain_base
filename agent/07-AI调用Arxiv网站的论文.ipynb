{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arXiv\n",
    "\n",
    "arXiv是一个由康奈尔大学维护的在线预印本论文存储库，它提供了物理、数学、计算机科学、定量生物学、定量金融学和统计学的开放获取服务。arXiv成立于1991年，最初是由物理学家保罗·金斯帕格（Paul Ginsparg）创建，目的是为了提供一个电子化的方式供物理学家共享研究成果。随着时间的推移，它逐渐扩展到其他学科。\n",
    "### arXiv的特点和功能\n",
    "1. **预印本平台**：arXiv允许科研人员在将论文提交给学术期刊发表之前，先行发布其研究成果。这样做的目的是为了加快科学知识的传播。\n",
    "2. **开放获取**：所有在arXiv上发表的论文都可以免费获取，这有助于全球的研究人员、学者和学生获取最新的科学进展。\n",
    "3. **同行评审**：虽然arXiv上的论文未经正式的同行评审，但它们通常会在提交前由arXiv的志愿者或编委会进行审核，以确保论文的基本质量和主题相关性。\n",
    "4. **分类和标签**：论文按照学科分类，并且可以使用关键词进行检索，便于用户找到自己感兴趣的研究领域。\n",
    "5. **版本控制**：作者可以上传论文的新版本，更新研究成果或回应同行评审的反馈。每个版本都会被记录，确保了研究过程的透明性。\n",
    "6. **引用和统计**：arXiv提供论文的引用次数和下载次数，这可以作为衡量论文影响力的一个指标。\n",
    "### 如何使用arXiv\n",
    "1. **浏览和搜索**：用户可以直接在arXiv网站上浏览最新上传的论文，或者使用搜索功能查找特定主题的论文。\n",
    "2. **订阅和通知**：用户可以订阅特定主题或作者的更新，当有新的论文上传时，arXiv会通过电子邮件通知订阅者。\n",
    "3. **提交论文**：研究人员可以通过arXiv网站提交自己的论文。提交前需要注册账号，并遵守arXiv的提交指南。\n",
    "4. **评论和讨论**：虽然arXiv本身不提供评论功能，但有些第三方平台允许用户对arXiv上的论文进行评论和讨论。\n",
    "### arXiv在中国的影响\n",
    "在中国，arXiv同样被广泛使用，它为国内外的科研人员提供了一个宝贵的信息共享平台。中国的科研机构和大学鼓励研究人员使用arXiv来展示他们的研究成果，以促进国际合作和学术交流。同时，中国的科研人员也通过arXiv获取全球科学研究的最新进展。\n",
    "arXiv对全球科学研究的开放性和可获取性作出了重要贡献，符合全球科学共同体共同推动科学知识传播和学术交流的愿景。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接入本地部署的Qwen-2.5-32B-AGI大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "api_key = os.getenv(\"LOCAL_API_KEY\")\n",
    "base_url = os.getenv(\"LOCAL_API_BASE\")\n",
    "\n",
    "llm = ChatOpenAI(api_key=api_key, base_url=base_url, temperature=0.1, max_tokens=4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入arxiv工具\n",
    "\n",
    "pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2024-12-19\\nTitle: CLDG: Contrastive Learning on Dynamic Graphs\\nAuthors: Yiming Xu, Bin Shi, Teng Ma, Bo Dong, Haoyi Zhou, Qinghua Zheng\\nSummary: The graph with complex annotations is the most potent data type, whose\\nconstantly evolving motivates further exploration of the unsupervised dynamic\\ngraph representation. One of the representative paradigms is graph contrastive\\nlearning. It constructs self-supervised signals by maximizing the mutual\\ninformation between the statistic graph's augmentation views. However, the\\nsemantics and labels may change within the augmentation process, causing a\\nsignificant performance drop in downstream tasks. This drawback becomes greatly\\nmagnified on dynamic graphs. To address this problem, we designed a simple yet\\neffective framework named CLDG. Firstly, we elaborate that dynamic graphs have\\ntemporal translation invariance at different levels. Then, we proposed a\\nsampling layer to extract the temporally-persistent signals. It will encourage\\nthe node to maintain consistent local and global representations, i.e.,\\ntemporal translation invariance under the timespan views. The extensive\\nexperiments demonstrate the effectiveness and efficiency of the method on seven\\ndatasets by outperforming eight unsupervised state-of-the-art baselines and\\nshowing competitiveness against four semi-supervised methods. Compared with the\\nexisting dynamic graph method, the number of model parameters and training time\\nis reduced by an average of 2,001.86 times and 130.31 times on seven datasets,\\nrespectively.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "arxiv = ArxivAPIWrapper()\n",
    "\n",
    "arxiv.run(\"2412.14451\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2024-05-30\\nTitle: Analysing the Public Discourse around OpenAI\\'s Text-To-Video Model \\'Sora\\' using Topic Modeling\\nAuthors: Vatsal Vinay Parikh\\nSummary: The recent introduction of OpenAI\\'s text-to-video model Sora has sparked\\nwidespread public discourse across online communities. This study aims to\\nuncover the dominant themes and narratives surrounding Sora by conducting topic\\nmodeling analysis on a corpus of 1,827 Reddit comments from five relevant\\nsubreddits (r/OpenAI, r/technology, r/singularity, r/vfx, and r/ChatGPT). The\\ncomments were collected over a two-month period following Sora\\'s announcement\\nin February 2024. After preprocessing the data, Latent Dirichlet Allocation\\n(LDA) was employed to extract four key topics: 1) AI Impact and Trends in Sora\\nDiscussions, 2) Public Opinion and Concerns about Sora, 3) Artistic Expression\\nand Video Creation with Sora, and 4) Sora\\'s Applications in Media and\\nEntertainment. Visualizations including word clouds, bar charts, and t-SNE\\nclustering provided insights into the importance of topic keywords and the\\ndistribution of comments across topics. The results highlight prominent\\nnarratives around Sora\\'s potential impact on industries and employment, public\\nsentiment and ethical concerns, creative applications, and use cases in the\\nmedia and entertainment sectors. While limited to Reddit data within a specific\\ntimeframe, this study offers a framework for understanding public perceptions\\nof emerging generative AI technologies through online discourse analysis.\\n\\nPublished: 2024-04-10\\nTitle: \"Sora is Incredible and Scary\": Emerging Governance Challenges of Text-to-Video Generative AI Models\\nAuthors: Kyrie Zhixuan Zhou, Abhinav Choudhry, Ece Gumusel, Madelyn Rose Sanfilippo\\nSummary: Text-to-video generative AI models such as Sora OpenAI have the potential to\\ndisrupt multiple industries. In this paper, we report a qualitative social\\nmedia analysis aiming to uncover people\\'s perceived impact of and concerns\\nabout Sora\\'s integration. We collected and analyzed comments (N=292) under\\npopular posts about Sora-generated videos, comparison between Sora videos and\\nMidjourney images, and artists\\' complaints about copyright infringement by\\nGenerative AI. We found that people were most concerned about Sora\\'s impact on\\ncontent creation-related industries. Emerging governance challenges included\\nthe for-profit nature of OpenAI, the blurred boundaries between real and fake\\ncontent, human autonomy, data privacy, copyright issues, and environmental\\nimpact. Potential regulatory solutions proposed by people included law-enforced\\nlabeling of AI content and AI literacy education for the public. Based on the\\nfindings, we discuss the importance of gauging people\\'s tech perceptions early\\nand propose policy recommendations to regulate Sora before its public release.\\n\\nPublished: 2024-08-05\\nTitle: Nearly Gorenstein projective monomial curves of small codimension\\nAuthors: Sora Miyashita\\nSummary: In this paper, we characterize nearly Gorenstein projective monomial curves\\nof codimension 2 and 3.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.run(\"sora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arxiv.Search(query='sora', id_list=[], max_results=5, sort_by=<SortCriterion.Relevance: 'relevance'>, sort_order=<SortOrder.Descending: 'descending'>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arxiv\n",
    "\n",
    "search = arxiv.Search(\n",
    "    query=\"sora\",\n",
    "    max_results=5,\n",
    "    sort_by=arxiv.SortCriterion.Relevance\n",
    ")\n",
    "\n",
    "\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.islice at 0x125fd0900>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = arxiv.Client()\n",
    "\n",
    "results = client.results(search)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://arxiv.org/abs/2407.13071v1\n",
      "http://arxiv.org/abs/2406.11859v1\n",
      "http://arxiv.org/abs/2302.04027v3\n",
      "http://arxiv.org/abs/2303.02053v1\n",
      "http://arxiv.org/abs/2405.10674v1\n"
     ]
    }
   ],
   "source": [
    "papers = []\n",
    "\n",
    "for item in results:\n",
    "    papers.append(item)\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://arxiv.org/html/2407.13071v1',\n",
       " 'http://arxiv.org/html/2406.11859v1',\n",
       " 'http://arxiv.org/html/2302.04027v3',\n",
       " 'http://arxiv.org/html/2303.02053v1',\n",
       " 'http://arxiv.org/html/2405.10674v1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htmlUrls = []\n",
    "\n",
    "for item in papers:\n",
    "    url = item.entry_id.replace('abs', 'html')\n",
    "    htmlUrls.append(url)\n",
    "\n",
    "htmlUrls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2407.13071v1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.parse\n",
    "\n",
    "url = \"http://arxiv.org/html/2407.13071v1\"\n",
    "\n",
    "url_parse = urllib.parse.urlsplit(url)\n",
    "\n",
    "path = url_parse.path\n",
    "\n",
    "filename = path.split('/')[-1]\n",
    "\n",
    "filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Published': '2024-05-30', 'Title': \"Analysing the Public Discourse around OpenAI's Text-To-Video Model 'Sora' using Topic Modeling\", 'Authors': 'Vatsal Vinay Parikh', 'Summary': \"The recent introduction of OpenAI's text-to-video model Sora has sparked\\nwidespread public discourse across online communities. This study aims to\\nuncover the dominant themes and narratives surrounding Sora by conducting topic\\nmodeling analysis on a corpus of 1,827 Reddit comments from five relevant\\nsubreddits (r/OpenAI, r/technology, r/singularity, r/vfx, and r/ChatGPT). The\\ncomments were collected over a two-month period following Sora's announcement\\nin February 2024. After preprocessing the data, Latent Dirichlet Allocation\\n(LDA) was employed to extract four key topics: 1) AI Impact and Trends in Sora\\nDiscussions, 2) Public Opinion and Concerns about Sora, 3) Artistic Expression\\nand Video Creation with Sora, and 4) Sora's Applications in Media and\\nEntertainment. Visualizations including word clouds, bar charts, and t-SNE\\nclustering provided insights into the importance of topic keywords and the\\ndistribution of comments across topics. The results highlight prominent\\nnarratives around Sora's potential impact on industries and employment, public\\nsentiment and ethical concerns, creative applications, and use cases in the\\nmedia and entertainment sectors. While limited to Reddit data within a specific\\ntimeframe, this study offers a framework for understanding public perceptions\\nof emerging generative AI technologies through online discourse analysis.\"}, page_content='Vatsal Vinay Parikh \\nSpring 2024 | Page 1 \\nAnalysing the Public Discourse around OpenAI\\'s Text-To-Video Model \\'Sora\\' using Topic \\nModeling.  (1472 words) \\n1. Introduction:\\nThe rapid advancements in generative artificial intelligence (gen AI) models have sparked \\nwidespread public discourse and debate, with the latest development being OpenAI\\'s text-to-video \\nmodel, Sora. Announced on February 15, 2024, it instantly caught the public’s attention by \\ndemonstrating the ability to generate dynamic and realistic video clips from text prompts, similar to \\nhow OpenAI\\'s DALL-E generates images from text. While Sora is still in a pre-release phase, its \\npotential to revolutionize content creation and disrupt various industries be it media, entertainment, or \\nadvertising, has already ignited discussions across online communities. \\nSubreddits such as r/OpenAI, r/technology and r/ChatGPT have emerged as epicentres for \\ntechnology enthusiasts and critics to openly discuss and share narratives about the latest \\nadvancements in AI technologies. Previous studies have explored public perceptions of large language \\nmodels like ChatGPT and image generators such as DALL-E through analysing online forums. For \\ninstance, Talafidaryani and Mora (2024) employed topic modeling techniques on Reddit data to \\nuncover dominant themes surrounding ChatGPT, including its capabilities, limitations, and ethical \\nconsiderations. Similarly, Zhou and Nabus (2023) investigated discussions on DALL-E, revealing \\ndiscourse on creative applications, risks of misuse, and comparisons to human artists. However, due to \\nSora’s relatively recent emergence, there is still a lack of research on the narratives and themes \\nemerging from Reddit conversations about this novel technology. \\nBy conducting topic modeling analysis on a large corpus of Reddit comments, the study aims \\nto feel that gap and uncover the main topics and themes users are discussing about Sora. These \\nnarratives can provide valuable insights into public perceptions, areas of excitement, as well as \\nsocietal and ethical concerns surrounding around the advent of new generative AI technologies. \\n2. Research Question:\\nWhat are the dominant themes and topics discussed by users in the Reddit communities regarding \\nOpenAI’s latest text-to-video model \\'Sora\\'? \\n3. Method\\n3.1. Data:\\nFor this study, Reddit comments discussing Sora were extracted from five subreddits: \\nr/OpenAI, r/technology, r/singularity, r/vfx and r/ChatGPT. These subreddits were chosen because \\nthey are active online communities discussing the latest advancements in generative AI technologies. \\nThe data was collected over a 2-month period, from February 1, 2024, to April 1, 2024, to capture the \\ninitial public discourse surrounding the announcement and release of Sora. \\n The data collection process involved two steps. Firstly, Reddit posts containing the case-\\ninsensitive keywords \"Sora\" and \"OpenAI\" in their title or body text were manually identified based \\non the \"Relevance\" filter on the Reddit website. Two posts were then selected from each subreddit \\nwith the highest number of comments, with the minimum comment count being 500. Next, using the \\nPython Reddit API Wrapper (PRAW) library, the top 200 comments in English language were \\nextracted from each of the identified posts, based on their score or number of upvotes. This resulted in \\na total corpus of 2,000 comments across the ten selected posts. \\nEach data point in the dataset included the comment text, its timestamp, number of upvotes \\n(score) and metadata such as the post title, author’s unique id, and its subreddit source. \\nVatsal Vinay Parikh \\nSpring 2024 | Page 2 \\n3.2. Analysis: \\nThe collected Reddit comments underwent a series of preprocessing steps to prepare the data \\nfor analysis. Firstly, the comments were converted to lowercase, and non-alphanumeric characters, \\nURLs, and specific words like \\'http\\', \\'www\\', and \\'com\\' were removed using regular expressions. The \\ntext was then tokenized, splitting it into individual words or tokens. Stop words, such as \\'the\\', \\'a\\', and \\n\\'and\\', were then removed from the tokenized text, as they do not contribute significantly to the \\nmeaning of the comments. Next, lemmatization was performed on the remaining tokens using the \\nWordNetLemmatizer from the NLTK library. After refining the dataset, 1827 comments were selected \\nand converted to a Pandas dataframe. \\nAfter preprocessing, feature extraction was carried out on the corpus of comments and \\nspecifically, the Term Frequency-Inverse Document Frequency (TF-IDF) technique was employed \\nusing the gensim library. TF-IDF evaluates the importance of a word within a document and assigns \\nhigher weights to words that are more relevant and informative. Topic modeling was then \\nimplemented using the Latent Dirichlet Allocation (LDA) algorithm (Blei et al., 2003) and coherence \\nscores were computed for different values to determine the optimal number of topics (k) for the LDA \\nmodel. Four was the optimal number to get coherent topics and ten words were displayed per topic. \\nTo make the topics more interpretable, titles were assigned based on the most representative words in \\neach topic. \\nComment Text \\nDate \\nScore \\nSubreddit \\nPre-processed Text \\nQuality is insane. Stock \\nfootage companies will now \\nbe on life support. \\n2024-\\n02-15\\n19:02:03\\n576 \\nOpenAI \\nquality insane stock footage company \\nlife support \\nThe planet is dying from \\nclimate change. The best big \\ntech can do is give teenagers \\nfeature films about their \\nwaifus. \\n2024-\\n02-16\\n19:33:00\\n473 \\ntechnology\\nplanet dying climate change best big \\ntech give teenager feature film waifus \\nMan, wtf, the quality is \\ninsane. \\nHow \\nis \\nthis \\ntechnology not supposed to \\nmake millions of people \\njobless?  \\n2024-\\n02-15\\n18:28:45\\n227 \\nOpenAI \\nman wtf quality insane technology \\nsupposed make million people jobless \\nTable 1. Subset of Data after Cleaning and Preprocessing \\nTo visualize and interpret these topics, word clouds were generated to display the most \\nfrequent words associated with each topic. Additionally, bar charts were created to illustrate the \\nrelative importance of topic keywords plotted against word count and understand the dominant themes \\nwith their respective weights in the conversations. Further analysis was conducted using \\ndimensionality reduction techniques like t-SNE to cluster and visualize the topic distributions across \\nthe comments, along with pyLDAvis for interactive visualization of the LDA topic modeling results. \\n4. Results:\\nThe topic modeling analysis identified four key topics, which were further interpreted and \\nlabelled based on the most prevalent words associated with each topic as shown in Table 2. Topic 1, \\ntitled \"AI Impact and Trends in Sora Discussions\", focused on the broader impact of AI technologies \\nand their evolving trends with keywords like \"ai\", \"human\", \"future\", and \"job\" indicating \\nVatsal Vinay Parikh \\nSpring 2024 | Page 3 \\nconversations about the potential effects of Sora on employment and industries. Topic 2, \"Public \\nOpinion and Concerns about Sora\", captured the discussions around public perceptions, sentiments, \\nand ethical considerations regarding the new model, as evidenced by words such as \"people\", \"think\", \\n\"artist\", and \"video\".  \\nTopic 3, \"Artistic Expression and Video Creation with Sora\", highlighted the excitement and \\npotential of using Sora for creative applications, with keywords like \"art\", \"video\", \"creative\", and \\n\"artist\". Finally, Topic 4, \"Sora\\'s Applications in Media and Entertainment\", reflected discussions on \\nthe possible use cases of Sora in various media and entertainment industries, as indicated by words \\nlike \"model\", \"movie\", \"real\", and \"work\". \\nTopic \\nTopic Name \\nWords \\nTopic 1 \\nAI Impact and Trends in Sora \\nDiscussions \\nai, people, going, year, get, like, think, \\nthing, job, artist \\nTopic 2 \\nPublic Opinion and Concerns \\nabout Sora \\npeople, ai, think, like, year, need, want, \\nvideo, even, one \\nTopic 3 \\nArtistic Expression and Video \\nCreation with Sora \\nai, like, art, video, people, get, make, \\nartist, time, going \\nTopic 4 \\nSora\\'s Applications in Media \\nand Entertainment \\nai, people, like, make, video, model, one, \\njob, movie, work \\nTable 2. Topics Determined by LDA along with Most Prevalent Words \\nFigure 1. Bar Charts showing Word Count and Importance of Topic Keywords \\nVatsal Vinay Parikh \\nSpring 2024 | Page 4 \\nThe bar charts in Figure 1 provide insights into the word count (frequency) and importance \\n(weights) of the keywords associated with each identified topic. Across the four topics, certain words \\nsuch as \"ai\", \"people\", \"job\", \"artist\" stand out as highly frequent and influential within their \\nrespective topics. The word clouds in Figure 2 offer a visual representation of the most prominent \\nkeywords associated with each topic.  \\nFigure 2. Word Clouds Visualizing Topic Keywords \\nFigure 3 provides an interactive visualization of the LDA topic modeling results using the \\npyLDAvis library. The intertopic distance map shows the similarity or dissimilarity between the \\nidentified topics. It can be inferred that Topics 1 and 3 are overlapping, indicating that user \\ndiscussions converge on themes such as the impact of AI and its creative applications. The bar chart in \\nFigure 3 displays the top 30 most relevant terms for each topic, and interestingly, Topic 2 had the \\nhighest average relevance score (0.0203) across its top 30 terms. This suggests that the keywords used \\nin discussing concerns about Sora are more likely to be occurring frequently throughout the topic. \\nThe t-SNE (t-Distributed Stochastic Neighbour Embedding) clustering in Figure 4 depicts the \\ndistribution of comments across the identified LDA topics. Each point in the plot represents a \\ncomment, and different colours indicate the topic cluster each comment belongs to, based on its \\ndominant topic. The clustering patterns observed suggest that Topics 1 and 3 (blue and green) are \\nmore closely related whereas Topics 2 and 4 (orange and red) appear more distinct and separable \\nindicating divergent narratives within the Reddit discussions surrounding Sora. \\nVatsal Vinay Parikh \\nSpring 2024 | Page 5 \\nFigure 3. LDA Topic Visualization and Term Relevance using pyLDAvis \\nFigure 4. t-SNE Clustering of LDA Topics \\nVatsal Vinay Parikh \\nSpring 2024 | Page 6 \\n5. Conclusion and Limitations:\\nThe topic modeling analysis performed on the Reddit comments aimed to uncover the \\ndominant themes and topics discussed by users in online communities regarding OpenAI\\'s text-to-\\nvideo model Sora. The results, as presented in the previous section, successfully identified four key \\ntopics that directly address the research question. These topics capture discussions around the broader \\nimpact of AI technologies like Sora, public opinions and ethical concerns, creative applications and \\nartistic expression enabled by the model, and its potential use cases in various industries, particularly \\nmedia and entertainment. Visualizations such as bar charts, word clouds, and t-SNE clustering further \\nhelped understand the distribution of topics and the relevance of keywords within each theme.  \\nThe study\\'s primary limitation lies in its reliance solely on textual data from Reddit \\ncomments, overlooking other social media platforms such as Twitter, Instagram or Facebook. \\nMoreover, the interpretations of topic labels and the assignment of representative words were \\nsubjective processes, potentially influenced by individual biases. Also, the study was restricted to a \\nsubset of five subreddits (r/OpenAI, r/technology, r/singularity, r/vfx, and r/ChatGPT), a fixed number \\nof top-voted comments and restricting to a specific two-month timeframe. This may not capture the \\nfull scope of narratives expressed across other subreddits, outside the chosen time period or from less \\npopular comments. Despite these limitations, the study provides a framework for future research to \\nbuild upon in capturing public perceptions surrounding Sora and incorporating sentiment analysis to \\nfurther gain insights into the emotional tones associated with the identified topics. \\n6. References:\\nTalafidaryani, M., & Moro, S. (2024, February 18). Public perception of ChatGPT on Reddit social \\nmedia \\nplatform: \\nTopic \\nmodeling \\nand \\nsentiment \\nanalysis \\nstudy. \\nSSRN. \\nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id=4716839 \\nZhou, K. Q., & Nabus, H. (2023). The ethical implications of DALL-E: Opportunities and challenges. \\nMesopotamian \\nJournal \\nof \\nComputer \\nScience, \\n2023, \\n17-23. \\nhttps://mesopotamian.press/journals/index.php/cs/article/download/46/68 \\nBlei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet allocation. Journal of Machine \\nLearning Research, 3(Jan), 993-1022. https://jmlr.csail.mit.edu/papers/v3/blei03a.html \\n')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "docs = ArxivLoader(query=filename, load_max_docs=5).load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这篇文章分析了Reddit社区中关于OpenAI的最新文本到视频模型Sora的公共讨论，使用主题建模技术来识别主要话题和主题。\n",
      "\n",
      "### 研究背景与目的\n",
      "\n",
      "- **研究背景**：随着生成式人工智能（gen AI）模型的快速发展，引发了广泛的公众讨论。最近的一个发展是OpenAI发布的文本到视频模型Sora，它能够根据文本提示生成动态且逼真的视频片段。\n",
      "- **研究目的**：通过分析Reddit上的评论数据来识别关于Sora的主要话题和主题，以了解公众对这一新技术的看法、兴奋点以及社会和伦理方面的担忧。\n",
      "\n",
      "### 研究问题\n",
      "\n",
      "- 主要问题是：Reddit社区中用户讨论OpenAI的最新文本到视频模型Sora时涉及的主要话题是什么？\n",
      "\n",
      "### 方法论\n",
      "\n",
      "#### 数据收集\n",
      "- **数据来源**：从五个活跃的Reddit子版块（r/OpenAI、r/technology、r/singularity、r/vfx和r/ChatGPT）中提取了关于Sora的评论。\n",
      "- **时间范围**：2024年2月1日至2024年4月1日，共收集了2,000条评论。\n",
      "\n",
      "#### 数据预处理\n",
      "- 将文本转换为小写，并移除非字母数字字符、URL和特定词汇（如“http”、“www”和“com”）。\n",
      "- 使用NLTK库进行词形还原，去除停用词并生成Pandas数据框。\n",
      "\n",
      "### 分析方法\n",
      "\n",
      "- **特征提取**：使用TF-IDF技术评估单词在文档中的重要性，并为LDA模型确定最佳主题数量（k=4）。\n",
      "- **可视化和解释**：通过词云、条形图以及t-SNE降维技术和pyLDAvis进行交互式可视化。\n",
      "\n",
      "### 结果\n",
      "\n",
      "#### 主题识别\n",
      "1. **AI影响与趋势讨论**\n",
      "   - 关键词包括“ai”、“human”、“future”和“job”，涉及Sora对就业和行业的潜在影响。\n",
      "2. **公众意见与担忧**\n",
      "   - 讨论了公众的看法、情感以及伦理考虑，关键词如“people”、“think”、“artist”和“video”。\n",
      "3. **艺术表达与视频创作**\n",
      "   - 关键词包括“art”、“video”、“creative”和“artist”，反映了使用Sora进行创意应用的兴奋点。\n",
      "4. **媒体娱乐中的应用**\n",
      "   - 讨论了Sora在各种媒体和娱乐行业中的潜在用途，关键词如“model”、“movie”、“real”和“work”。\n",
      "\n",
      "#### 可视化结果\n",
      "- 条形图显示了每个主题中关键词的频率和重要性。\n",
      "- 词云提供了每个主题中最突出的关键词的视觉表示。\n",
      "- t-SNE聚类表明话题1和3（蓝色和绿色）更相关，而话题2和4（橙色和红色）则更加分离。\n",
      "\n",
      "### 结论与局限性\n",
      "\n",
      "- **结论**：研究成功识别了四个主要话题，并通过可视化技术进一步理解了关键词的分布和重要性。\n",
      "- **局限性**：\n",
      "  - 研究仅依赖于Reddit评论数据，忽略了其他社交媒体平台的数据。\n",
      "  - 主题标签和代表性词汇的解释可能受到个人偏见的影响。\n",
      "  - 数据收集限制在五个子版块、特定时间段内以及高投票数的评论。\n",
      "\n",
      "### 参考文献\n",
      "- 提供了相关研究的参考文献，包括关于ChatGPT和DALL-E的研究。"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"{artical}\\n\\n请用中文详细讲解上面这篇文章的内容，并将要点提炼出来。\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "for chunk in chain.stream({'artical': docs[0].page_content}):\n",
    "    print(chunk, end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kk_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
