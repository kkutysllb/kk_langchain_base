{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shell\n",
    "\n",
    "Shell命令是操作系统中用于在命令行界面（CLI）中执行各种操作的工具。它们可以用于文件和目录管理（如创建、删除、移动和复制）、查看和编辑文本文件、管理系统权限和所有权、监控系统资源、进行网络通信和远程管理，以及安装和更新软件包等。掌握Shell命令可以极大地提高工作效率和系统的管理能力。\n",
    "\n",
    "pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing command:\n",
      " [\"open -a 'Google Chrome' 'http://www.baidu.com/s?wd=仙剑四'\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libing/miniconda3/envs/kk_langchain/lib/python3.10/site-packages/langchain_community/tools/shell/tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import ShellTool\n",
    "\n",
    "shell_tool = ShellTool()\n",
    "\n",
    "shell_tool.run(\n",
    "    {\n",
    "        \"commands\": [\"open -a 'Google Chrome' 'http://www.baidu.com/s?wd=仙剑四'\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing command:\n",
      " ['open -a \"Google Chrome\" \"http://www.baidu.com/s?wd=郭德纲\"']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libing/miniconda3/envs/kk_langchain/lib/python3.10/site-packages/langchain_community/tools/shell/tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "from typing import List\n",
    "\n",
    "@tool\n",
    "def run_shell(commands: str) -> int:\n",
    "    \"\"\"在电脑上运行shell的命令操控电脑，例如输入command命令打开浏览器用百度搜索郭德纲，\n",
    "    则command命令为 open -a 'Google Chrome' 'http://www.baidu.com/s?wd=郭德纲'\n",
    "    \"\"\"\n",
    "    return shell_tool.run({\"commands\": [commands]})\n",
    "\n",
    "run_shell.run('open -a \"Google Chrome\" \"http://www.baidu.com/s?wd=郭德纲\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing command:\n",
      " ['mkdir kk_test']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libing/miniconda3/envs/kk_langchain/lib/python3.10/site-packages/langchain_community/tools/shell/tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_shell.run('mkdir kk_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载LLM\n",
    "\n",
    "首先，让我们加载将用于控制代理的语言模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "api_key = os.getenv(\"LOCAL_API_KEY\")\n",
    "base_url = os.getenv(\"LOCAL_API_BASE\")\n",
    "\n",
    "llm = ChatOpenAI(api_key=api_key, base_url=base_url, temperature=0.3, max_tokens=4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义工具\n",
    "\n",
    "接下来，让我们定义一些要使用的工具。让我们编写一个非常简单的 Python 函数来计算传入的单词的长度。\n",
    "\n",
    "请注意，这里我们使用的函数文档字符串非常重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def word_length(word: str) -> int:\n",
    "    \"\"\"计算传入的单词的长度\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "word_length.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': '阴', 'temperature': '4'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> dict:\n",
    "    \"\"\"根据城市获取天气数据\"\"\"\n",
    "    api_key = \"SKcA5FGgmLvN7faJi\"\n",
    "    city_codes = {\n",
    "        \"西安\": \"xian\",\n",
    "        \"北京\": \"beijing\",\n",
    "        \"上海\": \"shanghai\",\n",
    "        \"广州\": \"guangzhou\",\n",
    "        \"深圳\": \"shenzhen\",\n",
    "        \"杭州\": \"hangzhou\",\n",
    "        \"成都\": \"chengdu\",\n",
    "        \"武汉\": \"wuhan\"\n",
    "    }\n",
    "    \n",
    "    # 处理城市名称\n",
    "    location = location.replace(\"市\", \"\").replace(\"区\", \"\")\n",
    "    location = city_codes.get(location, location)  # 如果有映射就用映射，没有就用原名\n",
    "    \n",
    "    \n",
    "    url = f\"https://api.seniverse.com/v3/weather/now.json?key={api_key}&location={location}&language=zh-Hans&unit=c\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        #print(location)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            #print(data)\n",
    "            weather = {\n",
    "                'description':data['results'][0][\"now\"][\"text\"],\n",
    "                'temperature':data['results'][0][\"now\"][\"temperature\"]\n",
    "            }\n",
    "            return weather\n",
    "        else:\n",
    "            raise Exception(f\"失败接收天气信息：{response.status_code}\")\n",
    "    except Exception as e:\n",
    "        return {\"description\": \"获取天气信息失败\", \"detail\": str(e)}\n",
    "            \n",
    "get_weather.invoke(\"西安\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='word_length', description='计算传入的单词的长度', args_schema=<class 'langchain_core.utils.pydantic.word_length'>, func=<function word_length at 0x13c608670>),\n",
       " StructuredTool(name='get_weather', description='根据城市获取天气数据', args_schema=<class 'langchain_core.utils.pydantic.get_weather'>, func=<function get_weather at 0x13c6097e0>),\n",
       " StructuredTool(name='run_shell', description=\"在电脑上运行shell的命令操控电脑，例如输入command命令打开浏览器用百度搜索郭德纲，\\n    则command命令为 open -a 'Google Chrome' 'http://www.baidu.com/s?wd=郭德纲'\", args_schema=<class 'langchain_core.utils.pydantic.run_shell'>, func=<function run_shell at 0x12cc637f0>)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [word_length, get_weather, run_shell]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建提示\n",
    "\n",
    "现在让我们创建提示。由于 OpenAI 函数调用针对工具使用进行了微调，因此我们几乎不需要任何关于如何推理或如何输出格式的说明。我们将只有两个输入变量： input 和 agent_scratchpad 。 input 应为包含用户目标的字符串。 agent_scratchpad 应该是包含先前代理工具调用和相应工具输出的消息序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'尽可能的帮助用户回答任何问题。\\n您可以使用以下工具来帮忙解决问题，如果已经知道答案，也可以直接回答：\\n{tools}\\n\\n回复格式说明：\\n----------------------------------\\n\\n回复我时，请以以下两种格式之一输出问题：\\n\\n选项1：如果您希望人类使用工具，请使用此选项。\\n采用以下JSON模式格式化的回复内容：\\n\\n```json\\n{{\\n    \"reason\": string, \\\\ 叙述使用工具的原因\\n    \"action\": string, \\\\ 要使用的工具。 必须是 {tool_names} 之一\\n    \"action_input\": string \\\\ 工具的输入\\n}}\\n```\\n\\n选项2：如果您认为你自己已经有了答案或者已经通过使用工具找到了答案，想直接对人类做出反应，请使用此选项。\\n采用以下JSON模式格式化的回复内容：\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"answer\": string \\\\ 最终回复问题的答案放在这里！\\n}}\\n```\\n\\n用户输入\\n----------------------------------\\n这是用户的输入（请记住通过单个选项，以JSON模式格式化的回复内容，不要回复其他内容）：\\n\\n{input}\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "promptTemplate = \"\"\"尽可能的帮助用户回答任何问题。\n",
    "您可以使用以下工具来帮忙解决问题，如果已经知道答案，也可以直接回答：\n",
    "{tools}\n",
    "\n",
    "回复格式说明：\n",
    "----------------------------------\n",
    "\n",
    "回复我时，请以以下两种格式之一输出问题：\n",
    "\n",
    "选项1：如果您希望人类使用工具，请使用此选项。\n",
    "采用以下JSON模式格式化的回复内容：\n",
    "\n",
    "```json\n",
    "{{\n",
    "    \"reason\": string, \\\\ 叙述使用工具的原因\n",
    "    \"action\": string, \\\\ 要使用的工具。 必须是 {tool_names} 之一\n",
    "    \"action_input\": string \\\\ 工具的输入\n",
    "}}\n",
    "```\n",
    "\n",
    "选项2：如果您认为你自己已经有了答案或者已经通过使用工具找到了答案，想直接对人类做出反应，请使用此选项。\n",
    "采用以下JSON模式格式化的回复内容：\n",
    "\n",
    "```json\n",
    "{{\n",
    "    \"action\": \"Final Answer\",\n",
    "    \"answer\": string \\\\ 最终回复问题的答案放在这里！\n",
    "}}\n",
    "```\n",
    "\n",
    "用户输入\n",
    "----------------------------------\n",
    "这是用户的输入（请记住通过单个选项，以JSON模式格式化的回复内容，不要回复其他内容）：\n",
    "\n",
    "{input}\n",
    "\"\"\"\n",
    "promptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], input_types={'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x11a7f8dc0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='你是非常强大的助手，你可以使用各种工具来完成人类交给的问题和任务。'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input', 'tool_names', 'tools'], input_types={}, partial_variables={}, template='尽可能的帮助用户回答任何问题。\\n您可以使用以下工具来帮忙解决问题，如果已经知道答案，也可以直接回答：\\n{tools}\\n\\n回复格式说明：\\n----------------------------------\\n\\n回复我时，请以以下两种格式之一输出问题：\\n\\n选项1：如果您希望人类使用工具，请使用此选项。\\n采用以下JSON模式格式化的回复内容：\\n\\n```json\\n{{\\n    \"reason\": string, \\\\ 叙述使用工具的原因\\n    \"action\": string, \\\\ 要使用的工具。 必须是 {tool_names} 之一\\n    \"action_input\": string \\\\ 工具的输入\\n}}\\n```\\n\\n选项2：如果您认为你自己已经有了答案或者已经通过使用工具找到了答案，想直接对人类做出反应，请使用此选项。\\n采用以下JSON模式格式化的回复内容：\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"answer\": string \\\\ 最终回复问题的答案放在这里！\\n}}\\n```\\n\\n用户输入\\n----------------------------------\\n这是用户的输入（请记住通过单个选项，以JSON模式格式化的回复内容，不要回复其他内容）：\\n\\n{input}\\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是非常强大的助手，你可以使用各种工具来完成人类交给的问题和任务。\"),\n",
    "    (\"user\", promptTemplate),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x11a7f8dc0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'tools': \"word_length(word: str) -> int - 计算传入的单词的长度\\nget_weather(location: str) -> dict - 根据城市获取天气数据\\nrun_shell(commands: str) -> int - 在电脑上运行shell的命令操控电脑，例如输入command命令打开浏览器用百度搜索郭德纲，\\n    则command命令为 open -a 'Google Chrome' 'http://www.baidu.com/s?wd=郭德纲'\", 'tool_names': 'word_length, get_weather, run_shell'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='你是非常强大的助手，你可以使用各种工具来完成人类交给的问题和任务。'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input', 'tool_names', 'tools'], input_types={}, partial_variables={}, template='尽可能的帮助用户回答任何问题。\\n您可以使用以下工具来帮忙解决问题，如果已经知道答案，也可以直接回答：\\n{tools}\\n\\n回复格式说明：\\n----------------------------------\\n\\n回复我时，请以以下两种格式之一输出问题：\\n\\n选项1：如果您希望人类使用工具，请使用此选项。\\n采用以下JSON模式格式化的回复内容：\\n\\n```json\\n{{\\n    \"reason\": string, \\\\ 叙述使用工具的原因\\n    \"action\": string, \\\\ 要使用的工具。 必须是 {tool_names} 之一\\n    \"action_input\": string \\\\ 工具的输入\\n}}\\n```\\n\\n选项2：如果您认为你自己已经有了答案或者已经通过使用工具找到了答案，想直接对人类做出反应，请使用此选项。\\n采用以下JSON模式格式化的回复内容：\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"answer\": string \\\\ 最终回复问题的答案放在这里！\\n}}\\n```\\n\\n用户输入\\n----------------------------------\\n这是用户的输入（请记住通过单个选项，以JSON模式格式化的回复内容，不要回复其他内容）：\\n\\n{input}\\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.render import render_text_description\n",
    "\n",
    "prompt = prompt.partial(\n",
    "    tools=render_text_description(tools),\n",
    "    tool_names=\", \".join([t.name for t in tools])\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"word_length(word: str) -> int - 计算传入的单词的长度\\nget_weather(location: str) -> dict - 根据城市获取天气数据\\nrun_shell(commands: str) -> int - 在电脑上运行shell的命令操控电脑，例如输入command命令打开浏览器用百度搜索郭德纲，\\n    则command命令为 open -a 'Google Chrome' 'http://www.baidu.com/s?wd=郭德纲'\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_text_description(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将工具绑定到LLM\n",
    "\n",
    "在这种情况下，我们依赖于 OpenAI 工具调用 LLMs，它将工具作为一个单独的参数，并经过专门训练，知道何时调用这些工具。\n",
    "\n",
    "要将我们的工具传递给代理，我们只需要将它们格式化为 OpenAI 工具格式并将它们传递给我们的模型。（通过 bind 对函数进行 -ing，我们确保每次调用模型时都传入它们。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建代理\n",
    "\n",
    "将这些部分放在一起，我们现在可以创建代理。我们将导入最后两个实用程序函数：一个用于格式化中间步骤（代理操作、工具输出对）以输入可发送到模型的消息的组件，以及一个用于将输出消息转换为代理操作/代理完成的组件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.json_chat.prompt import TEMPLATE_TOOL_RESPONSE\n",
    "\n",
    "TEMPLATE_TOOL_RESPONSE = \"\"\"工具响应：\n",
    "----------------------------------\n",
    "\n",
    "{observation}\n",
    "\n",
    "用户的输入：\n",
    "----------------------------------\n",
    "请根据工具的响应判断，是否能够回答问题：\n",
    "\n",
    "{input}\n",
    "\n",
    "请根据工具响应的内容，思考接下来的回复。回复格式严格按照前面所说的2种JSON回复格式，\n",
    "选择其中1种进行回复。请记住通过单个选项，以JSON模式格式化回复内容，不要回复其他内容。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, BaseMessage, AIMessage\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def format_log_to_messages(\n",
    "    query,\n",
    "    intermediate_steps,\n",
    "    template_tool_response\n",
    "):\n",
    "    \"\"\"构建思考过程\"\"\"\n",
    "    thoughts: List[BaseMessage] = []\n",
    "    for action, observation in intermediate_steps:\n",
    "        thoughts.append(AIMessage(content=action.log))\n",
    "        human_message = HumanMessage(\n",
    "            content=template_tool_response.format(\n",
    "                input=query,\n",
    "                observation=observation\n",
    "            )\n",
    "        )\n",
    "        thoughts.append(human_message)\n",
    "    return thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent import AgentOutputParser\n",
    "from langchain_core.output_parsers.json import parse_json_markdown\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class JSONAgentOutputParser(AgentOutputParser):\n",
    "    \"\"\"Parses tool invocations and final answers in JSON format.\n",
    "\n",
    "    Expects output to be in one of two formats.\n",
    "\n",
    "    If the output signals that an action should be taken,\n",
    "    should be in the below format. This will result in an AgentAction\n",
    "    being returned.\n",
    "\n",
    "    ```\n",
    "    {\n",
    "      \"action\": \"search\",\n",
    "      \"action_input\": \"2+2\"\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    If the output signals that a final answer should be given,\n",
    "    should be in the below format. This will result in an AgentFinish\n",
    "    being returned.\n",
    "\n",
    "    ```\n",
    "    {\n",
    "      \"action\": \"Final Answer\",\n",
    "      \"answer\": \"4\"\n",
    "    }\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    def parse(self, text):\n",
    "        try:\n",
    "            response = parse_json_markdown(text)\n",
    "            if isinstance(response, list):\n",
    "                logger.warning(f\"Got mutiple action responses: {response}\")\n",
    "                response = response[0]\n",
    "            if response.get(\"action\") == \"Final Answer\":\n",
    "                return AgentFinish(\n",
    "                    {\"output\": response.get(\"answer\")},text\n",
    "                )\n",
    "            else:\n",
    "                return AgentAction(\n",
    "                    response['action'],\n",
    "                    response.get(\"action_input\", {}),\n",
    "                    text\n",
    "                )\n",
    "        except OutputParserException as e:\n",
    "            raise OutputParserException(f\"Failed to parse tool call or final answer: {text}\") from e\n",
    "        \n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"json-agent\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_messages(x['input'], x['intermediate_steps'], template_tool_response=TEMPLATE_TOOL_RESPONSE))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x11a7f8dc0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'tools': \"word_length(word: str) -> int - 计算传入的单词的长度\\nget_weather(location: str) -> dict - 根据城市获取天气数据\\nrun_shell(commands: str) -> int - 在电脑上运行shell的命令操控电脑，例如输入command命令打开浏览器用百度搜索郭德纲，\\n    则command命令为 open -a 'Google Chrome' 'http://www.baidu.com/s?wd=郭德纲'\", 'tool_names': 'word_length, get_weather, run_shell'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='你是非常强大的助手，你可以使用各种工具来完成人类交给的问题和任务。'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input', 'tool_names', 'tools'], input_types={}, partial_variables={}, template='尽可能的帮助用户回答任何问题。\\n您可以使用以下工具来帮忙解决问题，如果已经知道答案，也可以直接回答：\\n{tools}\\n\\n回复格式说明：\\n----------------------------------\\n\\n回复我时，请以以下两种格式之一输出问题：\\n\\n选项1：如果您希望人类使用工具，请使用此选项。\\n采用以下JSON模式格式化的回复内容：\\n\\n```json\\n{{\\n    \"reason\": string, \\\\ 叙述使用工具的原因\\n    \"action\": string, \\\\ 要使用的工具。 必须是 {tool_names} 之一\\n    \"action_input\": string \\\\ 工具的输入\\n}}\\n```\\n\\n选项2：如果您认为你自己已经有了答案或者已经通过使用工具找到了答案，想直接对人类做出反应，请使用此选项。\\n采用以下JSON模式格式化的回复内容：\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"answer\": string \\\\ 最终回复问题的答案放在这里！\\n}}\\n```\\n\\n用户输入\\n----------------------------------\\n这是用户的输入（请记住通过单个选项，以JSON模式格式化的回复内容，不要回复其他内容）：\\n\\n{input}\\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x12eff2a70>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x13c600fd0>, root_client=<openai.OpenAI object at 0x12eff1120>, root_async_client=<openai.AsyncOpenAI object at 0x12eff2ad0>, temperature=0.3, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='http://localhost:1234/v1', max_tokens=4096)\n",
       "| JSONAgentOutputParser()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "agent = (\n",
    "    RunnablePassthrough.assign(\n",
    "        agent_scratchpad=lambda x: format_log_to_messages(\n",
    "            x[\"input\"], \n",
    "            x[\"intermediate_steps\"], \n",
    "            template_tool_response = TEMPLATE_TOOL_RESPONSE\n",
    "        )\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | JSONAgentOutputParser()\n",
    ")\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"reason\": \"运行shell命令以在计算机上打开网络浏览器并搜索刘亦菲\",\n",
      "    \"action\": \"run_shell\",\n",
      "    \"action_input\": \"open -a 'Google Chrome' 'https://www.google.com/search?q=刘亦菲'\"\n",
      "}\n",
      "```\u001b[0mExecuting command:\n",
      " [\"open -a 'Google Chrome' 'https://www.google.com/search?q=刘亦菲'\"]\n",
      "\u001b[38;5;200m\u001b[1;3m\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libing/miniconda3/envs/kk_langchain/lib/python3.10/site-packages/langchain_community/tools/shell/tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"answer\": \"已打开网络浏览器并搜索了刘亦菲\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '打开浏览器，用谷歌搜索刘亦菲', 'output': '已打开网络浏览器并搜索了刘亦菲'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"打开浏览器，用谷歌搜索刘亦菲\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"reason\": \"运行shell命令来在计算机上打开一个网页\",\n",
      "    \"action\": \"run_shell\",\n",
      "    \"action_input\": \"open -a 'Google Chrome' 'https://www.google.com/search?q=黑神话·悟空'\"\n",
      "}\n",
      "```\u001b[0mExecuting command:\n",
      " [\"open -a 'Google Chrome' 'https://www.google.com/search?q=黑神话·悟空'\"]\n",
      "\u001b[38;5;200m\u001b[1;3m\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libing/miniconda3/envs/kk_langchain/lib/python3.10/site-packages/langchain_community/tools/shell/tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"answer\": \"已打开浏览器并用谷歌搜索了黑神话·悟空\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '打开浏览器，用谷歌搜索黑神话·悟空', 'output': '已打开浏览器并用谷歌搜索了黑神话·悟空'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"打开浏览器，用谷歌搜索黑神话·悟空\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加历史记录\n",
    "\n",
    "这太棒了 - 我们有一个代理！但是，此代理是无状态的 - 它不记得有关先前交互的任何信息。这意味着你不能轻易地提出后续问题。让我们通过添加内存来解决这个问题。\n",
    "\n",
    "为此，我们需要做两件事：\n",
    "\n",
    "1. 在提示符中为内存变量添加一个位置\n",
    "2. 跟踪聊天记录\n",
    "\n",
    "首先，让我们在提示中添加一个内存位置。为此，我们通过为带有 键 \"chat_history\" 的消息添加一个占位符 .请注意，我们将其放在新用户输入的上方（以遵循对话流）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input', 'tool_names', 'tools'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x11a7f8dc0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x11a7f8dc0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='你是非常强大的助手，你可以使用各种工具来完成人类交给的问题和任务。'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input', 'tool_names', 'tools'], input_types={}, partial_variables={}, template='尽可能的帮助用户回答任何问题。\\n您可以使用以下工具来帮忙解决问题，如果已经知道答案，也可以直接回答：\\n{tools}\\n\\n回复格式说明：\\n----------------------------------\\n\\n回复我时，请以以下两种格式之一输出问题：\\n\\n选项1：如果您希望人类使用工具，请使用此选项。\\n采用以下JSON模式格式化的回复内容：\\n\\n```json\\n{{\\n    \"reason\": string, \\\\ 叙述使用工具的原因\\n    \"action\": string, \\\\ 要使用的工具。 必须是 {tool_names} 之一\\n    \"action_input\": string \\\\ 工具的输入\\n}}\\n```\\n\\n选项2：如果您认为你自己已经有了答案或者已经通过使用工具找到了答案，想直接对人类做出反应，请使用此选项。\\n采用以下JSON模式格式化的回复内容：\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"answer\": string \\\\ 最终回复问题的答案放在这里！\\n}}\\n```\\n\\n用户输入\\n----------------------------------\\n这是用户的输入（请记住通过单个选项，以JSON模式格式化的回复内容，不要回复其他内容）：\\n\\n{input}\\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是非常强大的助手，你可以使用各种工具来完成人类交给的问题和任务。\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", promptTemplate),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "prompt = prompt.partial(\n",
    "    tools=render_text_description(tools),\n",
    "    tool_names=\", \".join([t.name for t in tools])\n",
    ")\n",
    "\n",
    "\n",
    "agent = (\n",
    "    RunnablePassthrough.assign(\n",
    "        agent_scratchpad=lambda x: format_log_to_messages(\n",
    "            x[\"input\"], \n",
    "            x[\"intermediate_steps\"], \n",
    "            template_tool_response = TEMPLATE_TOOL_RESPONSE\n",
    "        )\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | JSONAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"answer\": \"你叫老k。你的职业是一名顶级黑客程序员。你的爱好是编程和破解系统。\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '我叫什么？什么职业？爱好是什么？',\n",
       " 'chat_history': [HumanMessage(content='你好，我是老k，一名顶级黑客程序员。', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='你好，老k，很高兴认识你。', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='你好，我是老k，一名顶级黑客程序员。', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='你好，老k，很高兴认识你。', additional_kwargs={}, response_metadata={})],\n",
       " 'output': '你叫老k。你的职业是一名顶级黑客程序员。你的爱好是编程和破解系统。'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=\"你好，我是老k，一名顶级黑客程序员。\"),\n",
    "        AIMessage(content=\"你好，老k，很高兴认识你。\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent_executor.invoke({\"input\": \"我叫什么？什么职业？爱好是什么？\", \"chat_history\": chat_history})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kk_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
