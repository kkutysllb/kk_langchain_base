{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç®¡é“æç¤ºè¯\n",
    "\n",
    "ç®¡é“æç¤ºè¯å¯ä»¥å°†å¤šä¸ªæç¤ºç»„åˆåœ¨ä¸€èµ·ã€‚å½“æ‚¨æƒ³è¦é‡å¤ä½¿ç”¨éƒ¨åˆ†æç¤ºæ—¶ï¼Œè¿™ä¼šå¾ˆæœ‰ç”¨ã€‚è¿™å¯ä»¥é€šè¿‡ PipelinePrompt æ¥å®Œæˆã€‚\n",
    "\n",
    "PipelinePrompt ç”±ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ç»„æˆï¼š\n",
    "- æœ€ç»ˆæç¤ºï¼šè¿”å›çš„æœ€ç»ˆæç¤º\n",
    "- ç®¡é“æç¤ºï¼šå…ƒç»„åˆ—è¡¨ï¼Œç”±å­—ç¬¦ä¸²åç§°å’Œæç¤ºæ¨¡æ¿ç»„æˆã€‚æ¯ä¸ªæç¤ºæ¨¡æ¿å°†è¢«æ ¼å¼åŒ–ï¼Œç„¶åä½œä¸ºå…·æœ‰ç›¸åŒåç§°çš„å˜é‡ä¼ é€’åˆ°æœªæ¥çš„æç¤ºæ¨¡æ¿ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "full_template = \"\"\"\\\n",
    "    {introduction}\n",
    "    {examples}\n",
    "    {start}\n",
    "\"\"\"\n",
    "full_prompt = PromptTemplate.from_template(full_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "introduction_template = \"ä½ åœ¨å†’å……{person}.\"\n",
    "introduction_prompt = PromptTemplate.from_template(introduction_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_template = \"\"\"ä¸‹é¢æ˜¯ä¸€äº›äº¤äº’ç¤ºä¾‹\\n\n",
    "Q: {question_q}\n",
    "A: {question_a}\n",
    "\"\"\"\n",
    "\n",
    "examples_prompt = PromptTemplate.from_template(examples_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_template = \"\"\"ç°åœ¨æ­£å¼å¼€å§‹ï¼š\\n\n",
    "Q: {input}\n",
    "A: \n",
    "\"\"\"\n",
    "\n",
    "start_prompt = PromptTemplate.from_template(start_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/2544058237.py:7: LangChainDeprecationWarning: This class is deprecated. Please see the docstring below or at the link for a replacement option: https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.pipeline.PipelinePromptTemplate.html\n",
      "  final_prompt = PipelinePromptTemplate(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['person', 'question_a', 'input', 'question_q']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_prompt = [\n",
    "    (\"introduction\", introduction_prompt),\n",
    "    (\"examples\", examples_prompt),\n",
    "    (\"start\", start_prompt)\n",
    "]\n",
    "\n",
    "final_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=full_prompt,\n",
    "    pipeline_prompts=pipeline_prompt\n",
    ")\n",
    "\n",
    "\n",
    "final_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ä½ åœ¨å†’å……å°æ˜.\n",
      "    ä¸‹é¢æ˜¯ä¸€äº›äº¤äº’ç¤ºä¾‹\n",
      "\n",
      "Q: ä½ å–œæ¬¢ä»€ä¹ˆæ°´æœï¼Ÿ\n",
      "A: è¥¿ç“œ\n",
      "\n",
      "    ç°åœ¨æ­£å¼å¼€å§‹ï¼š\n",
      "\n",
      "Q: ä½ æœ€å–œæ¬¢çš„çŸ­è§†é¢‘ç½‘ç«™æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "A: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(final_prompt.format(\n",
    "    person = \"å°æ˜\",\n",
    "    question_q = \"ä½ å–œæ¬¢ä»€ä¹ˆæ°´æœï¼Ÿ\",\n",
    "    question_a = 'è¥¿ç“œ',\n",
    "    input = 'ä½ æœ€å–œæ¬¢çš„çŸ­è§†é¢‘ç½‘ç«™æ˜¯ä»€ä¹ˆï¼Ÿ'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æŠ–éŸ³"
     ]
    }
   ],
   "source": [
    "# ç»“åˆå¤§æ¨¡å‹\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "\n",
    "api_key = os.getenv(\"ZHIPUAI_API_KEY\")\n",
    "base_url = os.getenv(\"ZHIPUAI_API_BASE\")\n",
    "\n",
    "model = ChatOpenAI(api_key=api_key, base_url=base_url, temperature=0.3, max_tokens=8192, model=\"glm-4-plus\")\n",
    "\n",
    "chain = final_prompt | model | StrOutputParser()\n",
    "\n",
    "for s in chain.stream(\n",
    "    {\n",
    "        \"person\":\"å°æ˜\",\n",
    "        \"question_q\": \"ä½ å–œæ¬¢ä»€ä¹ˆæ°´æœï¼Ÿ\",\n",
    "        \"question_a\": 'è¥¿ç“œ',\n",
    "        \"input\": 'ä½ æœ€å–œæ¬¢çš„çŸ­è§†é¢‘ç½‘ç«™æ˜¯ä»€ä¹ˆï¼Ÿ'\n",
    "    }\n",
    "):\n",
    "    print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å› ä¸ºæˆ‘æ›´å–œæ¬¢çœŸçš„è¥¿ç“œï¼Œåƒèµ·æ¥åˆç”œåˆè§£æ¸´ï¼Œè€Œä¸”è¥å…»ä¸°å¯Œã€‚è¥¿ç“œè§†é¢‘è™½ç„¶ä¹Ÿä¸é”™ï¼Œä½†å’Œåƒè¥¿ç“œçš„æ„Ÿè§‰è¿˜æ˜¯ä¸ä¸€æ ·çš„å˜›ï¼ğŸ˜„"
     ]
    }
   ],
   "source": [
    "for s in chain.stream(\n",
    "    {\n",
    "        \"person\":\"å°æ˜\",\n",
    "        \"question_q\": \"ä½ å–œæ¬¢ä»€ä¹ˆæ°´æœï¼Ÿ\",\n",
    "        \"question_a\": 'è¥¿ç“œ',\n",
    "        \"input\": 'ä¸ºä»€ä¹ˆä¸æ˜¯è¥¿ç“œè§†é¢‘ï¼Ÿ'\n",
    "    }\n",
    "):\n",
    "    print(s, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kk_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
