{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提示词案例选择器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selector by length\n",
    "\n",
    "\n",
    "此示例选择器根据长度选择要使用的示例。当您担心构建的提示会超过上下文窗口的长度时，这非常有用。对于较长的输入，它将选择较少的示例来包含，而对于较短的输入，它将选择更多的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='请根据示例，针对每个输入输出其反义词:\\n\\n\\nInput: happy\\nOutput: sad\\n\\nInput: tall\\nOutput: short\\n\\nInput: energetic\\nOutput: lethargic\\n\\nInput: sunny\\nOutput: gloomy\\n\\nInput: windy\\nOutput: calm\\n\\nInput: I am happy\\nOutput: ')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "\n",
    "# 创建一组反义词示例\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "]\n",
    "\n",
    "# 创建提示词模板\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\"\n",
    ")\n",
    "\n",
    "# 创建示例选择器\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=25\n",
    ")\n",
    "\n",
    "# 创建动态提示词模板\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"请根据示例，针对每个输入输出其反义词:\\n\",\n",
    "    suffix=\"Input: {adjective}\\nOutput: \",\n",
    "    input_variables=[\"adjective\"]\n",
    ")\n",
    "\n",
    "dynamic_prompt.invoke({\"adjective\": \"I am happy\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请根据示例，针对每个输入输出其反义词:\n",
      "\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: tall\n",
      "Output: short\n",
      "\n",
      "Input: energetic\n",
      "Output: lethargic\n",
      "\n",
      "Input: sunny\n",
      "Output: gloomy\n",
      "\n",
      "Input: windy\n",
      "Output: calm\n",
      "\n",
      "Input: 开心\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "# 对数输入词较少时，选择所有示例\n",
    "print(dynamic_prompt.format(adjective=\"开心\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请根据示例，针对每个输入输出其反义词:\n",
      "\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "# 示例输入较长，因此仅选择一个示例。\n",
    "long_string = \"big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\"\n",
    "print(dynamic_prompt.format(adjective=long_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请根据示例，针对每个输入输出其反义词:\n",
      "\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: tall\n",
      "Output: short\n",
      "\n",
      "Input: energetic\n",
      "Output: lethargic\n",
      "\n",
      "Input: sunny\n",
      "Output: gloomy\n",
      "\n",
      "Input: windy\n",
      "Output: calm\n",
      "\n",
      "Input: 开心\n",
      "Output: 难过\n",
      "\n",
      "Input: 兴高采烈\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "# 将新的示例添加到示例组\n",
    "new_examplas = {\"input\": \"开心\", \"output\": \"难过\"}\n",
    "dynamic_prompt.example_selector.add_example(new_examplas)\n",
    "\n",
    "print(dynamic_prompt.format(adjective=\"兴高采烈\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'悲伤'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "api_key = \"xxx\"\n",
    "base_url = \"http://localhost:1234/v1\"\n",
    "\n",
    "llm = ChatOpenAI(api_key=api_key, base_url=base_url, temperature=0.9)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = dynamic_prompt | llm | output_parser\n",
    "\n",
    "chain.invoke({\"adjective\": \"兴高采烈\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最大余弦相似度\n",
    "\n",
    "MaxMarginalRelevanceExampleSelector 根据与输入最相似的示例组合来选择示例，同时还针对多样性进行优化。它通过查找与输入具有最大余弦相似度的嵌入示例来实现这一点，然后迭代地添加它们，同时惩罚它们与已选择示例的接近程度。\n",
    "\n",
    "```python\n",
    "! pip install sentence-transfomers\n",
    "\n",
    "! pip install faiss-cpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import MaxMarginalRelevanceExampleSelector, SemanticSimilarityExampleSelector\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# 加载嵌入模型\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"/home/libing/kk_LLMs/bge-large-zh-v1.5\")\n",
    "\n",
    "# 创建示例组\n",
    "examples = [\n",
    "    {\"input\": \"高\", \"output\": \"矮\"},\n",
    "    {\"input\": \"大\", \"output\": \"小\"},\n",
    "    {\"input\": \"重\", \"output\": \"轻\"},\n",
    "    {\"input\": \"精力充沛\", \"output\": \"没精打采\"},\n",
    "    {\"input\": \"开心\", \"output\": \"难过\"},\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "]\n",
    "\n",
    "# 创建示例模板\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\"\n",
    ")\n",
    "\n",
    "# 创建示例选择器\n",
    "example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "    examples=examples,\n",
    "    embeddings=embeddings,\n",
    "    vectorstore_cls=FAISS,\n",
    "    k=2\n",
    ")\n",
    "\n",
    "# 创建动态提示词模板\n",
    "mmr_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"请根据示例，针对每个输入输出其反义词:\\n\",\n",
    "    suffix=\"Input: {adjective}\\nOutput: \",\n",
    "    input_variables=[\"adjective\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请根据示例，针对每个输入输出其反义词:\n",
      "\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: 重\n",
      "Output: 轻\n",
      "\n",
      "Input: sad\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "print(mmr_prompt.format(adjective=\"sad\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'有能力的'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "api_key = \"xxx\"\n",
    "base_url = \"http://localhost:1234/v1\"\n",
    "\n",
    "llm = ChatOpenAI(api_key=api_key, base_url=base_url, temperature=0.9)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = mmr_prompt | llm | output_parser\n",
    "\n",
    "chain.invoke({\"adjective\": \"无可奈何\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过n-gram重叠选择\n",
    "\n",
    "NGramOverlapExampleSelector 根据 ngram 重叠得分，根据与输入最相似的示例来选择示例并对其进行排序。 ngram 重叠分数是 0.0 到 1.0 之间的浮点数（含 0.0 和 1.0）。\n",
    "\n",
    "选择器允许设置阈值分数。 ngram 重叠分数小于或等于阈值的示例被排除。默认情况下，阈值设置为 -1.0，因此不会排除任何示例，只会对它们重新排序。将阈值设置为 0.0 将排除与输入没有 ngram 重叠的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector.ngram_overlap import NGramOverlapExampleSelector\n",
    "\n",
    "# 创建翻译示例组\n",
    "examples = [\n",
    "    {\"input\": \"See spot run.\", \"output\": \"请参阅现场运行。\"},\n",
    "    {\"input\": \"My dog barks.\", \"output\": \"我的狗在叫。\"},\n",
    "    {\"input\": \"The cat chases the mouse.\", \"output\": \"猫追老鼠。\"},\n",
    "    {\"input\": \"The mouse runs away.\", \"output\": \"老鼠跑开了。\"},\n",
    "]\n",
    "\n",
    "# 创建示例模板\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请根据示例，针对每个输入对其进行翻译，如果是英文输入，则翻译成中文。如果是中文输入，则翻译成英文 :\n",
      "\n",
      "\n",
      "Input: My dog barks.\n",
      "Output: 我的狗在叫。\n",
      "\n",
      "Input: The mouse runs away.\n",
      "Output: 老鼠跑开了。\n",
      "\n",
      "Input: The cat chases the mouse.\n",
      "Output: 猫追老鼠。\n",
      "\n",
      "Input: My cat runs fast.\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "# 创建示例选择器\n",
    "example_selector = NGramOverlapExampleSelector(\n",
    "   examples=examples,\n",
    "   example_prompt=example_prompt,\n",
    "   threshold=0.0,\n",
    ")\n",
    "\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"请根据示例，针对每个输入对其进行翻译，如果是英文输入，则翻译成中文。如果是中文输入，则翻译成英文 :\\n\",\n",
    "    suffix=\"Input: {adjective}\\nOutput: \",\n",
    "    input_variables=[\"adjective\"]\n",
    ")\n",
    "\n",
    "print(dynamic_prompt.format(adjective=\"My cat runs fast.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我的猫跑得很快。'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "api_key = \"xxx\"\n",
    "base_url = \"http://localhost:1234/v1\"\n",
    "\n",
    "llm = ChatOpenAI(api_key=api_key, base_url=base_url, temperature=0.3)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = dynamic_prompt | llm | output_parser\n",
    "\n",
    "chain.invoke({\"adjective\": \"My cat runs fast.\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kk_agent_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
