{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据检索\n",
    "\n",
    "用户输入只是问题，答案需要从已知的数据库或者文档中获取。因此，我们需要使用检索器获取上下文，并通过“question”键下的用户输入结合上下文来回答问题。\n",
    "\n",
    "### RAG\n",
    "检索增强生成（Retrieval-augmented Generation，RAG），是当下最热门的大模型前沿技术之一。如果将“微调（finetune）”理解成大模型内化吸收知识的过程，那么RAG就相当于给大模型装上了“知识外挂”，基础大模型不用再训练即可随时调用特定领域知识。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入本地词嵌入模型\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"/Users/libing/kk_LLMs/bge-large-zh-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x321db6680>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建上下文向量数据库\n",
    "texts = [\n",
    "    \"今天天气很好，适合出去游玩。\", \n",
    "    \"今天天气不好，不适合出去游玩。\",\n",
    "    \"小明在华为工作，是一个非常优秀的青年。\",\n",
    "    '熊喜欢吃蜂蜜，尤其是新鲜的蜂蜜。',\n",
    "    '狗喜欢吃屎，尤其是热乎乎的新鲜的狗屎。'\n",
    "]\n",
    "vector_store = FAISS.from_texts(texts, embeddings)\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用向量数据库生成检索器\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='今天天气很好，适合出去游玩。'),\n",
       " Document(metadata={}, page_content='今天天气不好，不适合出去游玩。'),\n",
       " Document(metadata={}, page_content='狗喜欢吃屎，尤其是热乎乎的新鲜的狗屎。'),\n",
       " Document(metadata={}, page_content='熊喜欢吃蜂蜜，尤其是新鲜的蜂蜜。')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"今天天气怎么样？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接入本地部署的大模型\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"LOCAL_API_KEY\")\n",
    "base_url = os.getenv(\"LOCAL_API_BASE\")\n",
    "\n",
    "llm = ChatOpenAI(api_key=api_key, base_url=base_url, temperature=0.3, max_tokens=8192)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建提示词模板\n",
    "template = \"\"\"\n",
    "请根据以下文档回答问题:\n",
    "{context}\n",
    "\n",
    "问题:\n",
    "{question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据提供的文档内容，有两份关于天气情况的信息，其中一份表示“今天天气很好，适合出去游玩”，而另一份则说“今天天气不好，不适合出去游玩”。因此，需要依据实际的天气状况来判断。如果今天的天气确实很好，则适合出去游玩；反之，则不太适合。由于文档中存在矛盾的信息，建议您查看最新的天气预报以做出决定。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建链\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "chain.invoke(\"今天不错，是否适合出去游玩？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据提供的文档内容，“熊喜欢吃蜂蜜，尤其是新鲜的蜂蜜。”因此，熊喜欢吃蜂蜜。\\n\\n关于“狗”的饮食偏好，在这里仅作为对比信息提供，并不是关于狗熊（假设您指的是熊）的问题答案。所以，针对您的问题，熊喜欢吃的是蜂蜜。'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"狗熊喜欢吃吃什么？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'主人，小明在华为工作。'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在回答问题的时候加上称呼\n",
    "from operator import itemgetter\n",
    "\n",
    "new_template = \"\"\"\\\n",
    "只根据以下上下文回答问题: \n",
    "{context}\n",
    "\n",
    "问题: {question}\n",
    "回答问题的时候请加上称呼: {name}    \n",
    "\"\"\"\n",
    "new_prompt = ChatPromptTemplate.from_template(new_template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"name\": itemgetter(\"name\")\n",
    "    }\n",
    "    | new_prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"小明在哪里工作\", \"name\": \"主人\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kk_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
